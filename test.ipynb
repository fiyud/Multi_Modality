{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\torchvision\\io\\image.py:13: UserWarning: Failed to load image Python extension: 'Could not find module 'C:\\Users\\Admin\\anaconda3\\envs\\xlstm\\Lib\\site-packages\\torchvision\\image.pyd' (or one of its dependencies). Try using the full path with constructor syntax.'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "INFO:speechbrain.utils.quirks:Applied quirks (see `speechbrain.utils.quirks`): [disable_jit_profiling, allow_tf32]\n",
      "INFO:speechbrain.utils.quirks:Excluded quirks specified by the `SB_DISABLE_QUIRKS` environment (comma-separated list): []\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\inspect.py:869: UserWarning: Module 'speechbrain.pretrained' was deprecated, redirecting to 'speechbrain.inference'. Please update your script. This is a change from SpeechBrain 1.0. See: https://github.com/speechbrain/speechbrain/releases/tag/v1.0.0\n",
      "  if ismodule(module) and hasattr(module, '__file__'):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "Device set to use cpu\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\tf_keras\\src\\backend.py:1400: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\tf_keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\tf_keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# from flask import Flask, request, jsonify\n",
    "import os\n",
    "from Audio2text.separate_audio import *\n",
    "from Audio2text import diarize_model\n",
    "from Denoiser.denoiser_run import denoise_audio\n",
    "from S2T import *\n",
    "from Speech_emo.emotion_predict import *\n",
    "from Speech_emo import *\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\Desktop\\Desktop\\aidemo\\aidemo\\PhoBertCNN\\phobert.py:119: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  phoBert = torch.load(phobert_path, map_location=device)\n",
      "c:\\Users\\Admin\\Desktop\\Desktop\\aidemo\\aidemo\\PhoBertCNN\\phobert.py:120: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  cnn = torch.load(cnn_path, map_location=device)\n"
     ]
    }
   ],
   "source": [
    "from PhoBertCNN.phobert import CNN,encoder_generator, predict_sentence, load_phobert_cnn, predict_text_emo\n",
    "\n",
    "phoBertCNN, cnn = load_phobert_cnn(r'C:\\Users\\Admin\\Desktop\\Desktop\\PhoBertCnn\\savefolder\\phoberttask2a_2.pt', r'C:\\Users\\Admin\\Desktop\\Desktop\\PhoBertCnn\\savefolder\\cnntask2a_2.pt', 'cpu')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_save_path = \"C:/Users/Admin/Desktop/Desktop/aidemo/emodata/emodata/b/recordings (36)_clip_4.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Denosing audio------\n",
      "Ran in 2.8753671646118164s\n",
      "------Diarizing audio------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\pyannote\\audio\\models\\blocks\\pooling.py:104: UserWarning: std(): degrees of freedom is <= 0. Correction should be strictly less than the reduction factor (input numel divided by output numel). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\ReduceOps.cpp:1823.)\n",
      "  std = sequences.std(dim=-1, correction=1)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             segment label     speaker   start     end\n",
      "0  [ 00:00:00.030 -->  00:00:00.419]     A  SPEAKER_00    30.0   420.0\n",
      "1  [ 00:00:00.722 -->  00:00:01.819]     B  SPEAKER_00   720.0  1820.0\n",
      "2  [ 00:00:02.342 -->  00:00:04.249]     C  SPEAKER_00  2340.0  4250.0\n",
      "3  [ 00:00:05.076 -->  00:00:05.734]     D  SPEAKER_01  5080.0  5730.0\n",
      "4  [ 00:00:05.279 -->  00:00:05.565]     E  SPEAKER_00  5280.0  5570.0\n",
      "5  [ 00:00:05.734 -->  00:00:09.008]     F  SPEAKER_00  5730.0  9010.0\n",
      "6  [ 00:00:05.920 -->  00:00:06.544]     G  SPEAKER_01  5920.0  6540.0\n",
      "-----Segmenting audio-----\n",
      "Saved segment_1.wav\n",
      "Saved segment_2.wav\n",
      "Saved segment_3.wav\n",
      "Saved segment_4.wav\n",
      "Saved segment_5.wav\n",
      "------Predicting emotion------\n",
      "1/1 [==============================] - 0s 244ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "Finished predicting text emotion in 0.57124924659729s\n",
      "------Transcribing audio------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\librosa\\core\\spectrum.py:266: UserWarning: n_fft=2048 is too large for input signal of length=1920\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "Due to a bug fix in https://github.com/huggingface/transformers/pull/28687 transcription using a multilingual Whisper will default to language detection followed by transcription instead of translation to English.This might be a breaking change for your use case. If you want to instead always translate your audio to English, make sure to pass `language='en'`.\n",
      "Passing a tuple of `past_key_values` is deprecated and will be removed in Transformers v4.43.0. You should pass an instance of `EncoderDecoderCache` instead, e.g. `past_key_values=EncoderDecoderCache.from_legacy_cache(past_key_values)`.\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\transformers\\models\\whisper\\generation_whisper.py:512: FutureWarning: The input name `inputs` is deprecated. Please make sure to use `input_features` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------Predicting emotion from text------\n",
      "Finished predicting emotion in 0.11990070343017578s\n",
      "-------Done--------, time:  51.172346115112305\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\anaconda3\\envs\\xlstm\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2673: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "denoised_output_folder = \"C:/Users/Admin/Desktop/Desktop/aidemo/test\"\n",
    "\n",
    "# step 1: denoise audio\n",
    "print(\"------Denosing audio------\")\n",
    "audio_denoised_link = denoise_audio(audio_link=file_save_path, output_folder=denoised_output_folder)\n",
    "    \n",
    "    # step 2: diaries audio using speaker diarization whisperx\n",
    "print(\"------Diarizing audio------\")\n",
    "audio = whisperx.load_audio(audio_denoised_link) # load and embed audio for diarization\n",
    "diarize_segments = get_DiarizeSegments(diarize_model = diarize_model,audio=audio, min_speakers = 2, max_speakers=2)\n",
    "print(diarize_segments)\n",
    "print('-----Segmenting audio-----')\n",
    "threshold = 600.0\n",
    "diarize_segments['duration'] = diarize_segments['end'] - diarize_segments['start']\n",
    "diarize_segments = diarize_segments[diarize_segments['duration'] >= threshold]\n",
    "\n",
    "segment_path = \"C:/Users/Admin/Desktop/Desktop/aidemo/test\"\n",
    "diarize_segments = cut_and_save_segments(audio_link=audio_denoised_link, diarize_segments=diarize_segments, format_type = 'wav', save_path = segment_path)\n",
    "\n",
    "# print(diarize_segments)\n",
    "# bonus: combine audio\n",
    "# print(\"------Combining audio------\")\n",
    "# audio_combine = combine_audio(diarize_segments, save_path= \"H://Learning Files/Project AI/Aidemo/aidemo/Audio_saving_file/Combined/\")\n",
    "# step 3: speech emotion\n",
    "print(\"------Predicting emotion------\")\n",
    "diarize_segments = predict_diarize_emo(diarize_segments)\n",
    "\n",
    "# step 4: speech to text\n",
    "print(\"------Transcribing audio------\")\n",
    "diarize_segments = text_diarize_save(diarize_segments)\n",
    "\n",
    "# step 4.5: text emotion classification\n",
    "print(\"------Predicting emotion from text------\")\n",
    "diarize_segments = predict_text_emo(diarize_segments, phoBertCNN, cnn, \"cpu\", encoder_generator=encoder_generator)\n",
    "\n",
    "end = time.time()\n",
    "# step 5: return to client\n",
    "print(\"-------Done--------, time: \", end-start)\t\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "      <th>label</th>\n",
       "      <th>speaker</th>\n",
       "      <th>start</th>\n",
       "      <th>end</th>\n",
       "      <th>duration</th>\n",
       "      <th>link</th>\n",
       "      <th>emotion</th>\n",
       "      <th>text</th>\n",
       "      <th>emotion_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[ 00:00:00.722 --&gt;  00:00:01.819]</td>\n",
       "      <td>B</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>720.0</td>\n",
       "      <td>1820.0</td>\n",
       "      <td>1100.0</td>\n",
       "      <td>C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...</td>\n",
       "      <td>[0.00015678243653383106, 5.688188253749615e-10...</td>\n",
       "      <td>{'text': 'bạn có biết tên đường hồng đô không.'}</td>\n",
       "      <td>[99.8142, 0.088789575, 0.097010195]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ 00:00:02.342 --&gt;  00:00:04.249]</td>\n",
       "      <td>C</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>2340.0</td>\n",
       "      <td>4250.0</td>\n",
       "      <td>1910.0</td>\n",
       "      <td>C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...</td>\n",
       "      <td>[16.58357048034668, 2.165447767765727e-05, 79....</td>\n",
       "      <td>{'text': 'cháu biết nhưng mà cháu không giàu ở...</td>\n",
       "      <td>[99.0192, 0.46434864, 0.51645166]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[ 00:00:05.076 --&gt;  00:00:05.734]</td>\n",
       "      <td>D</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>5080.0</td>\n",
       "      <td>5730.0</td>\n",
       "      <td>650.0</td>\n",
       "      <td>C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...</td>\n",
       "      <td>[5.7097117860394064e-06, 2.8175553185602435e-1...</td>\n",
       "      <td>{'text': 'yeah.'}</td>\n",
       "      <td>[99.814095, 0.14031184, 0.045598287]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[ 00:00:05.734 --&gt;  00:00:09.008]</td>\n",
       "      <td>F</td>\n",
       "      <td>SPEAKER_00</td>\n",
       "      <td>5730.0</td>\n",
       "      <td>9010.0</td>\n",
       "      <td>3280.0</td>\n",
       "      <td>C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...</td>\n",
       "      <td>[0.031319454312324524, 4.003322101198137e-05, ...</td>\n",
       "      <td>{'text': 'tại vì sao lại bị tàn tiền vì vì tự ...</td>\n",
       "      <td>[63.315, 7.362158, 29.322842]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[ 00:00:05.920 --&gt;  00:00:06.544]</td>\n",
       "      <td>G</td>\n",
       "      <td>SPEAKER_01</td>\n",
       "      <td>5920.0</td>\n",
       "      <td>6540.0</td>\n",
       "      <td>620.0</td>\n",
       "      <td>C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...</td>\n",
       "      <td>[3.531297206878662, 1.996564833461889e-06, 93....</td>\n",
       "      <td>{'text': 'unk sao nó điện.'}</td>\n",
       "      <td>[99.59135, 0.22801371, 0.18064085]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             segment label     speaker   start     end  \\\n",
       "1  [ 00:00:00.722 -->  00:00:01.819]     B  SPEAKER_00   720.0  1820.0   \n",
       "2  [ 00:00:02.342 -->  00:00:04.249]     C  SPEAKER_00  2340.0  4250.0   \n",
       "3  [ 00:00:05.076 -->  00:00:05.734]     D  SPEAKER_01  5080.0  5730.0   \n",
       "5  [ 00:00:05.734 -->  00:00:09.008]     F  SPEAKER_00  5730.0  9010.0   \n",
       "6  [ 00:00:05.920 -->  00:00:06.544]     G  SPEAKER_01  5920.0  6540.0   \n",
       "\n",
       "   duration                                               link  \\\n",
       "1    1100.0  C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...   \n",
       "2    1910.0  C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...   \n",
       "3     650.0  C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...   \n",
       "5    3280.0  C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...   \n",
       "6     620.0  C:/Users/Admin/Desktop/Desktop/aidemo/testsegm...   \n",
       "\n",
       "                                             emotion  \\\n",
       "1  [0.00015678243653383106, 5.688188253749615e-10...   \n",
       "2  [16.58357048034668, 2.165447767765727e-05, 79....   \n",
       "3  [5.7097117860394064e-06, 2.8175553185602435e-1...   \n",
       "5  [0.031319454312324524, 4.003322101198137e-05, ...   \n",
       "6  [3.531297206878662, 1.996564833461889e-06, 93....   \n",
       "\n",
       "                                                text  \\\n",
       "1   {'text': 'bạn có biết tên đường hồng đô không.'}   \n",
       "2  {'text': 'cháu biết nhưng mà cháu không giàu ở...   \n",
       "3                                  {'text': 'yeah.'}   \n",
       "5  {'text': 'tại vì sao lại bị tàn tiền vì vì tự ...   \n",
       "6                       {'text': 'unk sao nó điện.'}   \n",
       "\n",
       "                           emotion_text  \n",
       "1   [99.8142, 0.088789575, 0.097010195]  \n",
       "2     [99.0192, 0.46434864, 0.51645166]  \n",
       "3  [99.814095, 0.14031184, 0.045598287]  \n",
       "5         [63.315, 7.362158, 29.322842]  \n",
       "6    [99.59135, 0.22801371, 0.18064085]  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diarize_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "emotion_avg = pd.DataFrame(diarize_segments[\"emotion\"].tolist()).mean().tolist()\n",
    "emotion_text_avg = pd.DataFrame(diarize_segments[\"emotion_text\"].tolist()).mean().tolist()\n",
    "\n",
    "# Tạo DataFrame kết quả\n",
    "result = pd.DataFrame({\n",
    "    \"emotion_avg\": [emotion_avg],\n",
    "    \"emotion_text_avg\": [emotion_text_avg]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>emotion_avg</th>\n",
       "      <th>emotion_text_avg</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[4.029269926737197, 1.2736966474020292e-05, 94...</td>\n",
       "      <td>[92.3107681274414, 1.6567243337631226, 6.03250...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         emotion_avg  \\\n",
       "0  [4.029269926737197, 1.2736966474020292e-05, 94...   \n",
       "\n",
       "                                    emotion_text_avg  \n",
       "0  [92.3107681274414, 1.6567243337631226, 6.03250...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_emotion_labels = ['bad', 'happy', 'normal']  \n",
    "\n",
    "def calculate_emotion_avg(emotion_avg):\n",
    "    \n",
    "    bad_value = sum(emotion_avg[i] for i in [0, 1, 3])\n",
    "    happy_value = emotion_avg[2]  \n",
    "    normal_value = emotion_avg[4] \n",
    "    return bad_value, happy_value, normal_value\n",
    "\n",
    "def calculate_emotion_text_avg(emotion_text_avg):\n",
    "    clean_value = emotion_text_avg[0]\n",
    "    bad_text_value = sum(emotion_text_avg[i] for i in [1, 2])\n",
    "    return clean_value, bad_text_value\n",
    "\n",
    "new_emotion_values = []\n",
    "new_emotion_text_values = []\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "\n",
    "    bad, happy, normal = calculate_emotion_avg(row['emotion_avg'])\n",
    "    new_emotion_values.append([bad, happy, normal])\n",
    "    \n",
    "    clean, bad_text = calculate_emotion_text_avg(row['emotion_text_avg'])\n",
    "    new_emotion_text_values.append([clean, bad_text])\n",
    "\n",
    "result['new_emotion_values'] = new_emotion_values\n",
    "result['new_emotion_text_values'] = new_emotion_text_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hội thoại được phân loại là: bad\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Nhãn cảm xúc\n",
    "emotion_labels = ['sad', 'happy', 'angry', 'neutral', 'fear']\n",
    "text_emotion_labels = ['clean', 'offensive', 'hate']\n",
    "\n",
    "# Tạo danh sách các cảm xúc tiêu cực\n",
    "negative_emotions = {'sad', 'angry', 'fear'}\n",
    "negative_texts = {'offensive', 'hate'}\n",
    "\n",
    "def classify_conversation(emotion_values, text_emotion_values):\n",
    "    \"\"\"\n",
    "    Phân loại hội thoại dựa trên cảm xúc âm thanh và văn bản.\n",
    "    \n",
    "    emotion_values: Danh sách các vector cảm xúc của các segment\n",
    "    text_emotion_values: Danh sách các vector cảm xúc văn bản của các segment\n",
    "    \"\"\"\n",
    "    # Chuyển đổi emotion_values thành nhãn\n",
    "    for segment in emotion_values:\n",
    "        max_index = np.argmax(segment)\n",
    "        if emotion_labels[max_index] in negative_emotions:\n",
    "            return \"bad\"\n",
    "\n",
    "    # Chuyển đổi text_emotion_values thành nhãn\n",
    "    for segment in text_emotion_values:\n",
    "        max_index = np.argmax(segment)\n",
    "        if text_emotion_labels[max_index] in negative_texts:\n",
    "            return \"bad\"\n",
    "\n",
    "    return \"good\"\n",
    "\n",
    "# Ví dụ với dữ liệu từ ảnh\n",
    "emotion_values = [\n",
    "    [24.24, 3.19e-08, 1.84e-08, 75.75, 3.02e-05],  # neutral\n",
    "    [98.89, 3.44e-06, 3.62e-08, 1.10, 5.09e-05],   # happy\n",
    "    [99.97, 9.87e-05, 7.60e-08, 0.02, 9.78e-05],   # happy\n",
    "    [0.00072, 2.21e-11, 3.22e-08, 99.99, 2.94e-06], # neutral\n",
    "    [0.00082, 9.31e-12, 1.26e-08, 99.99, 2.13e-06]  # neutral\n",
    "]\n",
    "\n",
    "text_emotion_values = [\n",
    "    [99.81, 0.088, 0.097],  # clean\n",
    "    [99.01, 0.464, 0.516],  # clean\n",
    "    [99.81, 0.140, 0.045],  # clean\n",
    "    [63.31, 7.36, 29.32],   # offensive\n",
    "    [99.59, 0.228, 0.180]   # clean\n",
    "]\n",
    "\n",
    "# Gán nhãn hội thoại\n",
    "result = classify_conversation(emotion_values, text_emotion_values)\n",
    "print(f\"Hội thoại được phân loại là: {result}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  final_label\n",
      "0       happy\n"
     ]
    }
   ],
   "source": [
    "def get_highest_emotion(emotion_avg):\n",
    "    return max(range(len(emotion_avg)), key=lambda i: emotion_avg[i])\n",
    "\n",
    "def process_emotion_text(emotion_text_avg, highest_emotion_avg):\n",
    "   \n",
    "    clean = emotion_text_avg[0]\n",
    "    bad_text = sum(emotion_text_avg[i] for i in [1, 2])\n",
    "    if bad_text > clean:\n",
    "        return \"bad\" \n",
    "    else:\n",
    "        if highest_emotion_avg == 2:  # happy\n",
    "            return \"happy\"\n",
    "        elif highest_emotion_avg == 4:  # neutral\n",
    "            return \"neutral\"\n",
    "        else:\n",
    "            return \"bad\" \n",
    "        \n",
    "final_labels = []\n",
    "\n",
    "for index, row in result.iterrows():\n",
    "\n",
    "    highest_emotion_avg = get_highest_emotion(row['emotion_avg'])\n",
    "    \n",
    "    label = process_emotion_text(row['emotion_text_avg'], highest_emotion_avg)\n",
    "    \n",
    "    final_labels.append(label)\n",
    "\n",
    "result['final_label'] = final_labels\n",
    "\n",
    "print(result[['final_label']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fuse_convs(self):\n",
    "        \"\"\"Fuse parallel convolutions.\"\"\"\n",
    "        w = torch.zeros_like(self.conv.weight.data)\n",
    "        i = [x // 2 for x in w.shape[2:]]\n",
    "        w[:, :, i[0] : i[0] + 1, i[1] : i[1] + 1] = self.cv2.weight.data.clone()\n",
    "        self.conv.weight.data += w\n",
    "        self.__delattr__(\"cv2\")\n",
    "        self.forward = self.forward_fuse"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "xlstm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
